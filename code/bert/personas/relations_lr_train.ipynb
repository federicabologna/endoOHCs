{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1628,
     "status": "ok",
     "timestamp": 1673469078837,
     "user": {
      "displayName": "Rosamond Thalken",
      "userId": "03706515284749340063"
     },
     "user_tz": 360
    },
    "id": "eFyWXZGn0X97"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For machine learning tools and evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46562,
     "status": "ok",
     "timestamp": 1673469125395,
     "user": {
      "displayName": "Rosamond Thalken",
      "userId": "03706515284749340063"
     },
     "user_tz": 360
    },
    "id": "1MfxKZCB1QPE",
    "outputId": "3e7dc4c6-34b2-4712-c55e-a68bafcf6020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount the Google drive for access to files\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 178,
     "status": "ok",
     "timestamp": 1673469127725,
     "user": {
      "displayName": "Rosamond Thalken",
      "userId": "03706515284749340063"
     },
     "user_tz": 360
    },
    "id": "I27RJDGb3HxL"
   },
   "outputs": [],
   "source": [
    "# point to your project directory\n",
    "endo_dir = '/content/drive/MyDrive/endometriosis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5496,
     "status": "ok",
     "timestamp": 1673469134371,
     "user": {
      "displayName": "Rosamond Thalken",
      "userId": "03706515284749340063"
     },
     "user_tz": 360
    },
    "id": "bKVgd0qF1HdP",
    "outputId": "0fbe1f26-2311-4fd9-f47c-49a86e9c39be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of annotations is(1500, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of annotations is(1000, 13)\n",
      "number of annotations is(2000, 5)\n",
      "number of annotations is(1000, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "relation_names = ['FAMILY', 'DOCTORS', 'PARTNER', 'ENDO SUPPORT COMMUNITY']\n",
    "output_path = os.path.join(endo_dir, 'code', 'output', 'PERSONAS', 'LR')\n",
    "\n",
    "for relation in relation_names:\n",
    "  if relation == \"DOCTORS\":\n",
    "    annotation_file = \"relationships.csv\"\n",
    "  elif relation == \"ENDO SUPPORT COMMUNITY\":\n",
    "    annotation_file = \"relationships.csv\"\n",
    "  elif relation == \"FAMILY\":\n",
    "    annotation_file = \"combined_family.csv\"\n",
    "  elif relation == \"PARTNER\":\n",
    "    annotation_file = \"combined_partner.csv\"\n",
    "\n",
    "\n",
    "  # path of file with annotated data\n",
    "  annotations_file_path = os.path.join(endo_dir, 'labeling', 'annotated-data', 'formatted-csvs', annotation_file)\n",
    "\n",
    "  annotations_df = pd.read_csv(annotations_file_path)\n",
    "  print(f\"number of annotations is{annotations_df.shape}\")\n",
    "\n",
    "\n",
    "  texts = annotations_df.text.tolist()\n",
    "  vectorizer = TfidfVectorizer(\n",
    "      max_df = .90,\n",
    "      min_df = 3\n",
    "  )\n",
    "\n",
    "  X = vectorizer.fit_transform(texts) # vectorize tests\n",
    "  y = annotations_df[relation].tolist() # get true labels\n",
    "  lr = LogisticRegression()\n",
    "\n",
    "  train_texts, test_texts, train_labels, test_labels = train_test_split(X, y, test_size = 0.25) # split dataset in train and test sets\n",
    "\n",
    "  model = lr.fit(train_texts, train_labels) # fit logistic regression model\n",
    "  predicted_labels = model.predict(test_texts) # get predictions\n",
    "\n",
    "  class_report = classification_report(predicted_labels, test_labels, output_dict=True) # get evaluation report\n",
    "\n",
    "  class_report_df = pd.DataFrame(class_report).transpose()\n",
    "  file_name = os.path.join(f\"{relation}_lr.csv\", )\n",
    "  class_report_df.to_csv(os.path.join(output_path, file_name)) # save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKREpO9En5SE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPcayHY6mEYLeq+KpzKyUC1",
   "provenance": [
    {
     "file_id": "132ZSqf5Cgw3-aVtBdkAZtD-lTCN86Blj",
     "timestamp": 1657679655661
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
